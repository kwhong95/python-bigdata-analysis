# Chapter 03 데이터 과학 기반의 빅데이터 분석

## 01. 빅데이터 산업의 이해

<img width="714" alt="스크린샷 2021-03-06 오전 1 55 52" src="https://user-images.githubusercontent.com/70752848/110147501-179a3480-7e1f-11eb-980f-0569ee06bff2.png">

------

### 1. 빅데이터 플랫폼

> 데이터 플랫폼의 진화 : 파일 시스템 -> 데이터베이스와 데이터 웨어하우스 -> 빅데이터 플랫폼  
빅데이터 다양화로 인한 플랫폼 간 연동 문제 - NIST의 빅데이터 참조 아키텍처(표준화 활동)
  

<img width="955" alt="스크린샷 2021-03-06 오전 2 11 30" src="https://user-images.githubusercontent.com/70752848/110149345-45807880-7e21-11eb-92e0-32083713d090.png">

-----

#### 빅데이터 참조 아키텍처

<img width="825" alt="스크린샷 2021-03-06 오전 2 23 46" src="https://user-images.githubusercontent.com/70752848/110150774-fc312880-7e22-11eb-970b-123249009b26.png">

------
### 2. 빅데이터 에코시스템

> 빅데이터 플랫폼에 서비스 산업을 결합하여 고객에게 가치를 전달하는 유기적 공동체

<img width="598" alt="스크린샷 2021-03-06 오전 2 40 36" src="https://user-images.githubusercontent.com/70752848/110152675-6054ec00-7e25-11eb-901a-85ea1a5fee85.png">

-----

### 3. 빅데이터 서비스 프레임워크

> 빅데이터 시장의 공급자 분류에 대해서 알아보자

<img width="747" alt="스크린샷 2021-03-06 오전 2 51 23" src="https://user-images.githubusercontent.com/70752848/110153799-db6ad200-7e26-11eb-8691-cf05e30cea80.png">

----

#### 유형별 분류

<img width="907" alt="스크린샷 2021-03-06 오전 2 59 48" src="https://user-images.githubusercontent.com/70752848/110154802-06095a80-7e28-11eb-8a7c-5d4f90583b7a.png">

------

<img width="697" alt="스크린샷 2021-03-06 오전 3 18 11" src="https://user-images.githubusercontent.com/70752848/110156663-98aaf900-7e2a-11eb-9979-a40d47d1a2dd.png">

- A : 하드웨어 - 인프라 유형
  + 자체 데이터센터를 구축할 수 있게 해주는 서비스 유형
  + 사적 데이터 중심 : 기업형 솔루션
  + 공적 데이터 중심 : 플랫폼 서비스
  + IBM, HP, 오라클 -> 기업용 하드웨어 솔루션 제품

- B : 하드웨어 - 플랫폼 유형
  + 클라우드 기반의 서비스 제공
  + 기존 클라우드 컴퓨팅 시스템 사용 -> 빅데이터 서비스 제공

- C : 처리 소프트웨어 - 인프라 유형
  + 하드웨어 + 소프트웨어 서비스 제공
  + 대용량 데이터 -> 분산 저장 및 병렬 처리 인프라 + 처리 솔루션 제공
  + 오라클, IBM, HP, EMC -> 자사 하드웨어와 특화된 소프트웨어 통합 제공

- D : 처리 소프트웨어 - 플랫폼 유형
  + 오픈소스 기반의 소프트웨어 플랫폼 제공
  + 공급자 : 오픈소스 기반 빅데이터 처리 프로그램 제공
  + 소비자 : 클라우드 서비스로 빅데이터 처리 서비스 이용

- E : 분석 소프트웨어 - 플랫폼 유형
  + 소비자를 위한 분석 소프트웨어 제공
  + 빅데이터 솔루션으로 상품화 + 클라우드 컴퓨팅
  + 소비자는 자체 서버와 솔루션 구축하는 대신에 컴퓨팅 인프라에서 데이터를  
   저장 및 분석하는 프로그램 이용

- F : 분석 소프트웨어 - 애플리케이션 유형
  + 고객 맞춤형 솔루션 서비스 -> 데이터의 의미 파악 및 분석을 활용해 서비스 제공
  + 축적 데이터를 분석 후 결과의 의미를 파악하여 제공

## 02. 빅데이터 분석 방법과 접근법

### 1. 빅데이터 분석 방법
1. 통계 분석 : 통계 기법에 의한 분석 방법 - 가장 대표적 유형
2. 예측 분석 : 과거의 데이터와 변수 간의 관꼐를 이용해 새로운 변수 추정
3. 데이터 마이닝 분석 : 많은 데이터 속에 숨겨진 유용한 패턴을 추출하여 분류, 군집, 연관, 이상탐지 분석 등을 수행
4. 최적화 분석 : 주어진 제한 조건을 만족하면서 목적 함수를 최대화 또는 최소화하는 방법 탐색

### 2. 빅데이터 분석 접근법
1. **하향식 접근법** 
> 문제 해결 방법을 찾기 위한 데이터 수집 및 분석
- 근본 원인 파악 후 분석 과제 도출한 뒤 해결 방안 도출
- 도출된 해결 방안에 대한 실현 가능성과 우선순위를 결정하기 위해 데이터를 수집, 가공, 분석하는 접근법
- '수요 기반 분석 과제 도출 방식' : 해결할 이슈나 문제를 정의한 뒤 문제 해결 시나리오를 수립한 뒤 문제 해결 시나리오에 적합한 데이터와 필요한 분석 기법을 찾아서 활용하는 방식
- 위 과정 속에서 데이터 분석은 문제 해결을 가능하게 하는 **실행 동인 역할**을 수행

2. **상향식 접근법**
> 데이터를 분석하여 의미있는 관계나 패턴을 찾아 지식을 발견하고 문제를 해결하는 방식
- 시각화를 통해 의미있는 패텬을 파악한 뒤 이를 적용해 문제를 해결하는 데이터 기반의 접근법
- '데이터 주도 분석 과제 도출 방식' : 다양한 데이터 분석을 통해 이슈나 문제에 대한 해결 과제를 새로운 시각으로 도출
- 다양한 데이터 간의 교차 분석 및 상호 연광성 분석을 수행하여 인지하지 못한 패턴과
정보를 찾아내고 해결 과제를 도출
- 위 과정 속에서 데이터는  **추진 동인 역할**을 수행

3. **프로토타이핑 접근법**
> 빅데이터 환경의 **불확실성**을 고려한 방식
- 프로토타입을 만들어 분석을 시도한 뒤 결과를 확인하고 개선
- 작업을 반복하여 소비자가 원하는 결과를 도출

> 빅데이터 분석 프로젝트 진행 시 세가지 접근법 중 하나를 사용하기보단 프로젝트의 성격과 요구사항, 환경에 따라 접근법을 조합하거나 변형해서 사용

## 03. 빅데이터 분석을 위한 데이터 과학 방법론

[**데이터 과학 방법론 6단계**]
<img width="874" alt="스크린샷 2021-03-06 오후 3 18 04" src="https://user-images.githubusercontent.com/70752848/110197487-2ae4e880-7e8f-11eb-8800-1acb80a55503.png">

### [STEP 1] : 연구 목표 설정

- 무엇을 분석하는 가
- 결과가 어디에 왜 필요한가
- 어떤 데이터가 필요한가
- 프로젝트 일정은 어떻게 정할 것인가

> 모든 참여자가 연구 목표를 정의하고 산출물과 일정 등의 계획을 합의한 뒤 **프로젝트 헌장**을 작성하여 공식 프로젝트로 선정한다.

### [STEP 2] : 데이터 수집
> 프로젝트에 필요한 데이터의 위치와 형태를 확인하고 원시 데이터를 수집
- 내부 데이터베이스나 데이터 저장소를 이용
- 외부의 정부기관 및 공적 조직에서 공유하는 데이터를 활용

[**다양한 데이터 수집 기술**]
| 수집 기술 | 설명 | 수집 데이터 |
| --- | --- | --- |
| 크롤링 | SNS, 뉴스, 웹 정보처럼 인터넷에서 제공하는 데이터 수집 | 웹 추출 데이터|
| FTP | - TCP/IP 프로토콜을 활용하는 인터넷 서버에서 각종 파일을 송수신 <br> - 보안을 강화하려면 SFTP 사용을 고려 <br> - 서버 간 연동시 전용 네트워크 구축을 고려 | 파일 |
| Open API | 서비스, 데이터 둥을 어디서나 쉽게 이용하도록 개방된 API 데이터 수집 방식을 제공 <br> - 다양한 애플리케이션을 개발할 수 있도록 개발자와 소비자에게 공개 | 실시간 수집 데이터 |
| RSS | 웹 기반의 최신 정보를 공유하기 위한 XML 기반의 콘텐츠 배급 프로토콜 | XML 기반 웹 콘텐츠 |
| 스트리밍 | 인터넷에서 실시간으로 음성/오디오/비디오 데이터를 수집하는 기술 | 음성/오디오/비디오와 실시간 수집 데이터 |
| 로그 수집기 | - 웹 서버 로그, 웹 로그, 트랜잭션 로그, 클릭 로그, DB 로그 등 각종 로그 데이터를 수집하는 오픈 소스 기술 <br> 예 : Chukwam, Flume, Scribe | 로그 |
| RDB 수집기 | - 관계형 데이터베이스에서 정형 데이터 수집 후 HDFS(하둡 분산 파일 시스템)나 HBase와 같은 NoSQL에 저장하는 오프소스 기술 <br> - 예 : Sqoop, Direct JDBC/ODBC | RDB 기반 데이터 |

[**데이터의 유형과 종류에 따른 수집 기술 예시**]
| 유형 | 종류 | 수집 기술 |
| --- | --- | --- |
| 정형 데이터 | RDB, 스프레드시트 | ETL, FTP, Open API |
| 반정형 데이터 | HTML, XML, JSON, 웹 문서, 웹 로그, 센서 데이터 | 크롤링, RSS, Open API, FTP |
| 비정형 데이터 | 소셜 데이터, 문서(워드, 한글), 이미지, 오디오, 비디오, IoT | 크롤링, RSS, Open API, 스트리밍, FTP |

-----

### [STEP 3] : 데이터 준비
> 수집한 원시 데이터의 품질을 높이기 위해 정제 후 사용 가능한 형태로 가공

| 종류 | 설명 |
| --- | --- |
| 데이터 여과 | 오류 발견, 보정, 삭제, 중복성 확인 등 과정을 통해 데이터 품질 향상 |
| 데이터 정제 | 결측치는 채워 넣고 이상치는 식별 또는 제거하고 잡음이 섞인 데이터는 평활화하여 데이트 불일치성을 교정 |
| 데이터 통합 | 데이터 분석이 용이하도록 데이터 및 연계가 필요한 데이터(또는 데이터 베이스)를 통합 |
| 데이터 축소 | 분석 시간을 단축하기 위해 분석에 사용하지 않은 항목은 제거 |
| 데이터 변환 | - 데이터 분석에 용이한 형태로 데이터 유형을 변환 <br> - 정규화, 집합화, 요약, 계층 생성 등의 방법 활용 <br> - ETL 도구를 제공 |

----

### [STEP 4] : 데이터 탐색 
> 데이터와 변수 간의 관계나 상호 작용을 이해하기 위한 단계 

[**탐색적 데이터 분석(Exploratory Data Analysis)**]
- 변수 간의 관련성
- 데이터의 분포, 편차, 패턴 존재 여부 확인
- 꺽은선 그래프, 히스토그램, 분포도 등과 같은 그래픽 기법 사용

### [STEP: 5] : 데이터 모델링
> 이전 단계에서 얻은 데이터 탐색 결과로 프로젝트에 대한 답을 찾는 단계

- 변수를 선택해 모델을 구성하고 실행 및 평가하는 과정을 반복 수행하여 문제 해결 모델을 완성
- 데이터의 특성과 목적에 따라 모델 유형을 선택

[ **데이터 분석 모델의 종류** ]

- 통계 분석 모델 : 전통적 분석 기법 : 수치형 데이터에 사용 - 확률 기반으로 현상을 추정 및 예측 
  + 기술 통계
    + **평균**(산술 평균, 중앙값, 최빈값)
    + **분산**
    + **표준 편차**
  + 상관 분석
    + 선형적 관계를 분석하는 기법
    + **독립적 관계 - 상관 관계** 의 강도 분석
  + 회귀 분석
    + 연속형 변수에 대해 독립 변수와 종속 변수 사이의 상관관계에 따른 수학적 모델인 **선형적 관계식**을 구해 어떤 독립 변수가 주어졌을 때 이에 따른 **종속 변수를 예측**하거나 수학적 모델이 얼마나 잘 설명하고 있는 지 판별하기 위한 **적합도를 측정**하는 분석 기법
  + 분산 분석
    + 다수의 집단 비교시 집단 내의 분산, 총평균과 각 집단의 평균의 차이로 생긴 집단간 분산의 비교를 통해 F분포로 가설을 검증
  + 주성분 분석
    + 다양한 변수를 분석하는 다변량 분석 - 많은 변수로 부터 몇 개의 **주성분을 추출**하는 기법 - **자원 축소 목적**
- 데이터 마이닝 모델 : 패턴 인식, AI, 머신러닝, 딥러닝 등을 이용하여 대용량 데이터에 숨겨진 데이터 간의 **상호 관련성** 및 **유용한 정보** 추출
  + 예측 : 대용량 데이터 집합 내의 패턴으로 미래 예측
  + 분류 : 일정한 집단에 대해 특정한 정의로 분류 및 구분을 추론
  + 군집화 : 구체적인 특성을 공유하는 자료를 분류 - 미리 정의된 특성에 대한 정보를 가지지 않는다는 점 ( 분류와의 차이점 )
  + 패턴 분석 : 동시에 발생한 사건 간의 상호연관성을 탐색 
  + 순차 패턴 분석 : 연관 규칙에 시간 개념을 반영하여 시계열에 따른 패턴의 상호 연관성을 탐색
- 텍스트 마이닝 모델 : 텍스트 기반의 데이터로 부터 새로운 정보를 발견 - 텍스트 처리 과정 및 기법
  + 정보 검색 
  + 정보 추출 
  + 정보 체계화
  + 정보 분석
- 소셜 네트워크 분석 모델 : 언어 분석 기반의 정보 추출 - 대용량의 소셜 미디어 데이터에서 이슈를 탐지하고 시간 관계에 따라 이슈가 유통되는 전체 과정을 모니터링하고 추이를 분석하는 기법

### [STEP 6] : 결과 발표 및 분석 자동화
> 프로젝트 수행 결과가 연구 목표를 달생했는지를 당사자, 특히 의사 결정자에게 이해시키고 가능하다면 이후 유사 프로젝트 수행을 위해 분석 과정을 자동화